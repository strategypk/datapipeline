{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f1a2dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt                                        \n",
    "import seaborn as sns                                                  \n",
    "from collections import Counter                                           \n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import spacy\n",
    "# import contractions\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator         \n",
    "import nltk                                                            \n",
    "import matplotlib.pylab as plt \n",
    "from nltk.corpus import wordnet\n",
    "import warnings                                                           \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from nltk.stem.porter import PorterStemmer  \n",
    "from bs4 import BeautifulSoup\n",
    "from spacy import displacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "fff28de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "model_name = \"yjernite/bart_eli5\"\n",
    "sa=SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f9664b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "99d7e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3089219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import emoji\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7d22daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# imported sklearn mertrics for classification report and error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c2fd6051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None) #to display all data of a dataframe column without truncation\n",
    "\n",
    "import warnings #import warning module\n",
    "warnings.filterwarnings('ignore') #set to ignore any warning \n",
    "from IPython.core.display import HTML #import HTML module\n",
    "HTML(\"<style>.container { width:95% !important; }</style>\") #set HTML style to get more space in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "259e5d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Business Rule\n",
    "def Customer_Service_Business_Rule(tweet_str, idx):\n",
    "    print(\"Customer Tweet: \", tweet_str)\n",
    "    if idx == 0:\n",
    "        return (\"Bot (Negative Sentiment): I'm sorry you feel this way\")\n",
    "    elif idx ==1:\n",
    "        return (\"Bot:(Neutral Sentiment)  --no response--\")\n",
    "    elif idx ==2:\n",
    "        return (\"Bot: Glad, you are happy with our service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "154dbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Customer_Service_Business_Rule_Transformer(tweet_str, idx):\n",
    "    print(\"Tweet Summarization: \", tweet_str)\n",
    "    if idx == 0:\n",
    "        return (\"Bot (Negative Sentiment): I'm sorry you feel this way\")\n",
    "    elif idx ==1:\n",
    "        return (\"Bot:(Neutral Sentiment)  --no response--\")\n",
    "    elif idx ==2:\n",
    "        return (\"Bot: Glad, you are happy with our service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c6649821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Economic Baseline Business Rule for CSR\n",
    "def Language_Used(tweet_str, idx):\n",
    "    print(\"Customer Tweet: \", tweet_str)\n",
    "    if idx == 0:\n",
    "        return (\"negative\")\n",
    "    elif idx ==1:\n",
    "        return (\"polite\") \n",
    "    elif idx ==2:\n",
    "        return (\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6a727f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "try:\n",
    "#     metricset = pd.read_excel('data\\\\transformer_metrics.xlsx')\n",
    "#     metricset = pd.read_csv('data\\\\tweets.csv')\n",
    "    metricset = pd.read_excel('data\\\\tweets_100.xlsx')\n",
    "\n",
    "except:\n",
    "    print(\"Error Loading file(s),  current working directory:\", format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e7b82007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  100 non-null    object\n",
      " 1   text       100 non-null    object\n",
      " 2   BERT       100 non-null    object\n",
      " 3   ELECTRA    100 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "metricset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d5dd17a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment    object\n",
      "text         object\n",
      "BERT         object\n",
      "ELECTRA      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (metricset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f1b38540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metricset['text'] = metricset['text'].astype(str)\n",
    "# metricset = metricset.applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fbae94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5e00f6f",
   "metadata": {},
   "source": [
    "#### Randomize the model choice, Double blind the business rule function - hypothesis wins if generations still shows trend of polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6a146e08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>BERT</th>\n",
       "      <th>ELECTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united On top of that I paid for 1st class and my wife got stuck in coach.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united Ph the pat answers are BS. After I was denied boarding it sat at the gate until 9:05! Your employees totally suck.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@United Over the last week, United has provided me with the worst customer service experience of my life. Disgusting. #united</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united 24 hrs since flight landed and ZERO info on my missing bag? rough ETA would be hugely helpful + restore some confidence</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united big surprise #nogate waiting for our plane. Same fucken issues everything I fly you. #fail #worstairlineever</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  negative   \n",
       "1  negative   \n",
       "2  negative   \n",
       "3  negative   \n",
       "4  negative   \n",
       "\n",
       "                                                                                                                              text  \\\n",
       "0                                                      @united On top of that I paid for 1st class and my wife got stuck in coach.   \n",
       "1       @united Ph the pat answers are BS. After I was denied boarding it sat at the gate until 9:05! Your employees totally suck.   \n",
       "2    @United Over the last week, United has provided me with the worst customer service experience of my life. Disgusting. #united   \n",
       "3  @united 24 hrs since flight landed and ZERO info on my missing bag? rough ETA would be hugely helpful + restore some confidence   \n",
       "4             @united big surprise #nogate waiting for our plane. Same fucken issues everything I fly you. #fail #worstairlineever   \n",
       "\n",
       "       BERT   ELECTRA  \n",
       "0  negative  negative  \n",
       "1  negative  negative  \n",
       "2  negative  positive  \n",
       "3  negative  negative  \n",
       "4  negative  negative  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "cb8ea901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vader(text):\n",
    "#     print(text)\n",
    "    score = sa.polarity_scores(text)\n",
    "    idx = np.argmax([score.get('neg'),score.get('neu'),score.get('pos')],0)\n",
    "    if idx == 0:\n",
    "        return 'negative'\n",
    "    elif idx == 1:\n",
    "        return 'neutral'\n",
    "    elif idx == 2:\n",
    "        return 'positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2901c7",
   "metadata": {},
   "source": [
    "### Model 1 : Vader Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9ee30169",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempset = metricset['text']\n",
    "metricset['Vader'] = tempset.apply(Vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "00e95fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>BERT</th>\n",
       "      <th>ELECTRA</th>\n",
       "      <th>Vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united On top of that I paid for 1st class and my wife got stuck in coach.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united Ph the pat answers are BS. After I was denied boarding it sat at the gate until 9:05! Your employees totally suck.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@United Over the last week, United has provided me with the worst customer service experience of my life. Disgusting. #united</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united 24 hrs since flight landed and ZERO info on my missing bag? rough ETA would be hugely helpful + restore some confidence</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united big surprise #nogate waiting for our plane. Same fucken issues everything I fly you. #fail #worstairlineever</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  negative   \n",
       "1  negative   \n",
       "2  negative   \n",
       "3  negative   \n",
       "4  negative   \n",
       "\n",
       "                                                                                                                              text  \\\n",
       "0                                                      @united On top of that I paid for 1st class and my wife got stuck in coach.   \n",
       "1       @united Ph the pat answers are BS. After I was denied boarding it sat at the gate until 9:05! Your employees totally suck.   \n",
       "2    @United Over the last week, United has provided me with the worst customer service experience of my life. Disgusting. #united   \n",
       "3  @united 24 hrs since flight landed and ZERO info on my missing bag? rough ETA would be hugely helpful + restore some confidence   \n",
       "4             @united big surprise #nogate waiting for our plane. Same fucken issues everything I fly you. #fail #worstairlineever   \n",
       "\n",
       "       BERT   ELECTRA    Vader  \n",
       "0  negative  negative  neutral  \n",
       "1  negative  negative  neutral  \n",
       "2  negative  positive  neutral  \n",
       "3  negative  negative  neutral  \n",
       "4  negative  negative  neutral  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "289e54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def DistilBERT(text):\n",
    "#     score = sa.polarity_scores(text)\n",
    "#     idx = np.argmax([score.get('neg'),score.get('neu'),score.get('pos')],0)\n",
    "#     if idx == 0:\n",
    "#         return 'negative'\n",
    "#     elif idx == 1:\n",
    "#         return 'neutral'\n",
    "#     elif idx == 2:\n",
    "#         return 'positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82449a",
   "metadata": {},
   "source": [
    "### BERT Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe764c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6be2f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertForTokenClassification\n",
    "# import torch\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertForTokenClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# inputs = tokenizer(\"bad\", return_tensors=\"pt\")\n",
    "# labels = torch.tensor([1] * inputs[\"input_ids\"].size(1)).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "# outputs = model(**inputs, labels=labels)\n",
    "# loss = outputs.loss\n",
    "# logits = outputs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdae1121",
   "metadata": {},
   "source": [
    "### DistilBERT Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "301ab70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistilBert_Classifier(text):\n",
    "   #DistilBertForSequenceClassification(default model)\n",
    "    nlp_cls = pipeline('sentiment-analysis') \n",
    "    config = False\n",
    "#     print(text)\n",
    "    if config==True:\n",
    "        print(nlp_cls.model.config)\n",
    "    cls = nlp_cls(text)\n",
    "#     print(cls)\n",
    "    return cls[0].get('label').lower() \n",
    "# text = metricset['text'][0]\n",
    "## DistilBert_sentiment_classification =DistilBert_Classifier(text,False) \n",
    "# DistilBert_sentiment_classification =DistilBert_Classifier(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "330c5536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistilBert_sentiment_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1c004299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(DistilBert_sentiment_classification)\n",
    "# DistilBert_sentiment_classification[0].get('label').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "31c7a15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n"
     ]
    }
   ],
   "source": [
    "tempset = metricset['text']\n",
    "metricset['DistilBERT'] = tempset.apply(DistilBert_Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e7b5f9b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>BERT</th>\n",
       "      <th>ELECTRA</th>\n",
       "      <th>Vader</th>\n",
       "      <th>DistilBERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united On top of that I paid for 1st class and my wife got stuck in coach.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united Ph the pat answers are BS. After I was denied boarding it sat at the gate until 9:05! Your employees totally suck.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@United Over the last week, United has provided me with the worst customer service experience of my life. Disgusting. #united</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united 24 hrs since flight landed and ZERO info on my missing bag? rough ETA would be hugely helpful + restore some confidence</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united big surprise #nogate waiting for our plane. Same fucken issues everything I fly you. #fail #worstairlineever</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  negative   \n",
       "1  negative   \n",
       "2  negative   \n",
       "3  negative   \n",
       "4  negative   \n",
       "\n",
       "                                                                                                                              text  \\\n",
       "0                                                      @united On top of that I paid for 1st class and my wife got stuck in coach.   \n",
       "1       @united Ph the pat answers are BS. After I was denied boarding it sat at the gate until 9:05! Your employees totally suck.   \n",
       "2    @United Over the last week, United has provided me with the worst customer service experience of my life. Disgusting. #united   \n",
       "3  @united 24 hrs since flight landed and ZERO info on my missing bag? rough ETA would be hugely helpful + restore some confidence   \n",
       "4             @united big surprise #nogate waiting for our plane. Same fucken issues everything I fly you. #fail #worstairlineever   \n",
       "\n",
       "       BERT   ELECTRA    Vader DistilBERT  \n",
       "0  negative  negative  neutral   negative  \n",
       "1  negative  negative  neutral   negative  \n",
       "2  negative  positive  neutral   negative  \n",
       "3  negative  negative  neutral   negative  \n",
       "4  negative  negative  neutral   negative  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed842721",
   "metadata": {},
   "source": [
    "### RoBERTa Sentiment Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9e210805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class for data preparation\n",
    "class SimpleDataset:\n",
    "    def __init__(self, tokenized_texts):\n",
    "        self.tokenized_texts = tokenized_texts\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_texts[\"input_ids\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.tokenized_texts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "811390c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\228e83e1ade2247aebc5f0725e330fa58dedee3d9eec36c9249f25084a946130.1aece0680a18a95d51d6e1a5f83631412da37b87db65380c52052161354505ba\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/vocab.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\b522c6365937d6f39045d31ba715daafd39604f04b745f9d3d5cd622ecd74408.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/merges.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\a1fbb0cbc048b898b9adb0aa928b6bde50f393786ec91ffe195736820c42b02f.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/special_tokens_map.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\e7bd01a8669e2d76258ba5ab711ba48da69b2dfc573c7b02566c0e73bd4583f4.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n",
      "loading file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\9f284be68d0cfa5298eea908fc7f51cc7e0b01c7aaf2eba99c70d938b169bfe8.ba4a40df74471cdc82cd580af48bbbcfd25e9095a9d4bb296f711f3af7e2619e\n",
      "loading configuration file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\228e83e1ade2247aebc5f0725e330fa58dedee3d9eec36c9249f25084a946130.1aece0680a18a95d51d6e1a5f83631412da37b87db65380c52052161354505ba\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8fda88182b287ca423f06cae23d4c4701aaba057b65b3a691930de41e6537b3b.f135db3906a2e0c1f328a5920119f906cfb27b985cb0bfe7ef94434bdb31d031\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at siebert/sentiment-roberta-large-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model, create trainer\n",
    "model_name = \"siebert/sentiment-roberta-large-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "trainer = Trainer(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5f1f6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['My flight got delayed, somebody is going to get hurt, real bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "5313a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = tokenizer(texts,truncation=True,padding=True)\n",
    "pred_dataset = SimpleDataset(tokenized_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a9eb62f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(pred_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ac8c3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform predictions to labels\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "labels = pd.Series(preds).map(model.config.id2label)\n",
    "scores = (np.exp(predictions[0])/np.exp(predictions[0]).sum(-1,keepdims=True)).max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "46231dea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My flight got delayed, somebody is going to get hurt, real bad</td>\n",
       "      <td>0</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             text  pred  \\\n",
       "0  My flight got delayed, somebody is going to get hurt, real bad     0   \n",
       "\n",
       "      label     score  \n",
       "0  NEGATIVE  0.999489  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(texts,preds,labels,scores)), columns=['text','pred','label','score'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0c9ad7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RoBERTa_Classifier(text):\n",
    "    tokenized_texts = tokenizer(texts,truncation=True,padding=True)\n",
    "    pred_dataset = SimpleDataset(tokenized_texts)\n",
    "    predictions = trainer.predict(pred_dataset)\n",
    "    preds = predictions.predictions.argmax(-1)\n",
    "    labels = pd.Series(preds).map(model.config.id2label)\n",
    "    scores = (np.exp(predictions[0])/np.exp(predictions[0]).sum(-1,keepdims=True)).max(1)\n",
    "    return str(labels[0]).lower() \n",
    "# text = metricset['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7bf4ec4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RoBERTa_Classifier(\"My flight got delayed, somebody is going to get hurt, real bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "cceec315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "tempset = metricset['text']\n",
    "metricset['RoBERTa'] = tempset.apply(RoBERTa_Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "439045c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>BERT</th>\n",
       "      <th>ELECTRA</th>\n",
       "      <th>Vader</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united On top of that I paid for 1st class and my wife got stuck in coach.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united Ph the pat answers are BS. After I was denied boarding it sat at the gate until 9:05! Your employees totally suck.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@United Over the last week, United has provided me with the worst customer service experience of my life. Disgusting. #united</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united 24 hrs since flight landed and ZERO info on my missing bag? rough ETA would be hugely helpful + restore some confidence</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united big surprise #nogate waiting for our plane. Same fucken issues everything I fly you. #fail #worstairlineever</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united You're trying to solve problem of your own making. Charging for checked luggage forces checking at gate. Brilliant.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united we've been waiting 45 min for a gate at SFO... Yet so many of them are free.  Your excellence in operational efficiency is showing</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>negative</td>\n",
       "      <td>@United \"delayed due to customer service\" Huh? http://t.co/XlTV5z6sT1</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united what about the poor customer service at checkin at Kansas KCI?!? That's it???</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united except all of that delayed the flight anyway.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0   negative   \n",
       "1   negative   \n",
       "2   negative   \n",
       "3   negative   \n",
       "4   negative   \n",
       "..       ...   \n",
       "95  negative   \n",
       "96  negative   \n",
       "97  negative   \n",
       "98  negative   \n",
       "99  negative   \n",
       "\n",
       "                                                                                                                                          text  \\\n",
       "0                                                                  @united On top of that I paid for 1st class and my wife got stuck in coach.   \n",
       "1                   @united Ph the pat answers are BS. After I was denied boarding it sat at the gate until 9:05! Your employees totally suck.   \n",
       "2                @United Over the last week, United has provided me with the worst customer service experience of my life. Disgusting. #united   \n",
       "3              @united 24 hrs since flight landed and ZERO info on my missing bag? rough ETA would be hugely helpful + restore some confidence   \n",
       "4                         @united big surprise #nogate waiting for our plane. Same fucken issues everything I fly you. #fail #worstairlineever   \n",
       "..                                                                                                                                         ...   \n",
       "95                 @united You're trying to solve problem of your own making. Charging for checked luggage forces checking at gate. Brilliant.   \n",
       "96  @united we've been waiting 45 min for a gate at SFO... Yet so many of them are free.  Your excellence in operational efficiency is showing   \n",
       "97                                                                       @United \"delayed due to customer service\" Huh? http://t.co/XlTV5z6sT1   \n",
       "98                                                       @united what about the poor customer service at checkin at Kansas KCI?!? That's it???   \n",
       "99                                                                                       @united except all of that delayed the flight anyway.   \n",
       "\n",
       "        BERT   ELECTRA    Vader DistilBERT   RoBERTa  \n",
       "0   negative  negative  neutral   negative  negative  \n",
       "1   negative  negative  neutral   negative  negative  \n",
       "2   negative  positive  neutral   negative  negative  \n",
       "3   negative  negative  neutral   negative  negative  \n",
       "4   negative  negative  neutral   negative  negative  \n",
       "..       ...       ...      ...        ...       ...  \n",
       "95  negative  negative  neutral   positive  negative  \n",
       "96  negative  negative  neutral   positive  negative  \n",
       "97  negative   neutral  neutral   negative  negative  \n",
       "98  negative  negative  neutral   negative  negative  \n",
       "99  negative  negative  neutral   negative  negative  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "1f9600ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metricset.to_excel('data\\\\classification_saved.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6200e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Score = pd.DataFrame(\n",
    "    {'sentiment': [\"0.0\",\"0.0\",\"0.0\",\"0.0\"],\n",
    "     'Vader': [\"0.0\",\"0.0\",\"0.0\",\"0.0\"],\n",
    "     'BERT': [\"0.0\",\"0.0\",\"0.0\",\"0.0\"],\n",
    "     'DistilBERT': [\"0.0\",\"0.0\",\"0.0\",\"0.0\"],\n",
    "     'RoBERTa': [\"0.0\",\"0.0\",\"0.0\",\"0.0\"],\n",
    "     'ELECTRA': [\"0.0\",\"0.0\",\"0.0\",\"0.0\"]\n",
    "    },\n",
    "    index=['F1_Macro', 'F1_Macro_Neutral_Score','F1_Macro_Positive_Score','F1_Macro_Negative_Score']\n",
    ")\n",
    "# Model_Score=Model_Score.rename_axis('Dark_Side')\n",
    "Model_Score = Model_Score.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c3e71bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Vader</th>\n",
       "      <th>BERT</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>ELECTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1_Macro</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Neutral_Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Positive_Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Negative_Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sentiment  Vader  BERT  DistilBERT  RoBERTa  ELECTRA\n",
       "F1_Macro                       0.0    0.0   0.0         0.0      0.0      0.0\n",
       "F1_Macro_Neutral_Score         0.0    0.0   0.0         0.0      0.0      0.0\n",
       "F1_Macro_Positive_Score        0.0    0.0   0.0         0.0      0.0      0.0\n",
       "F1_Macro_Negative_Score        0.0    0.0   0.0         0.0      0.0      0.0"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "08e86881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>BERT</th>\n",
       "      <th>ELECTRA</th>\n",
       "      <th>Vader</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united On top of that I paid for 1st class and my wife got stuck in coach.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united Ph the pat answers are BS. After I was denied boarding it sat at the gate until 9:05! Your employees totally suck.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@United Over the last week, United has provided me with the worst customer service experience of my life. Disgusting. #united</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united 24 hrs since flight landed and ZERO info on my missing bag? rough ETA would be hugely helpful + restore some confidence</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united big surprise #nogate waiting for our plane. Same fucken issues everything I fly you. #fail #worstairlineever</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united You're trying to solve problem of your own making. Charging for checked luggage forces checking at gate. Brilliant.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united we've been waiting 45 min for a gate at SFO... Yet so many of them are free.  Your excellence in operational efficiency is showing</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>negative</td>\n",
       "      <td>@United \"delayed due to customer service\" Huh? http://t.co/XlTV5z6sT1</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united what about the poor customer service at checkin at Kansas KCI?!? That's it???</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united except all of that delayed the flight anyway.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0   negative   \n",
       "1   negative   \n",
       "2   negative   \n",
       "3   negative   \n",
       "4   negative   \n",
       "..       ...   \n",
       "95  negative   \n",
       "96  negative   \n",
       "97  negative   \n",
       "98  negative   \n",
       "99  negative   \n",
       "\n",
       "                                                                                                                                          text  \\\n",
       "0                                                                  @united On top of that I paid for 1st class and my wife got stuck in coach.   \n",
       "1                   @united Ph the pat answers are BS. After I was denied boarding it sat at the gate until 9:05! Your employees totally suck.   \n",
       "2                @United Over the last week, United has provided me with the worst customer service experience of my life. Disgusting. #united   \n",
       "3              @united 24 hrs since flight landed and ZERO info on my missing bag? rough ETA would be hugely helpful + restore some confidence   \n",
       "4                         @united big surprise #nogate waiting for our plane. Same fucken issues everything I fly you. #fail #worstairlineever   \n",
       "..                                                                                                                                         ...   \n",
       "95                 @united You're trying to solve problem of your own making. Charging for checked luggage forces checking at gate. Brilliant.   \n",
       "96  @united we've been waiting 45 min for a gate at SFO... Yet so many of them are free.  Your excellence in operational efficiency is showing   \n",
       "97                                                                       @United \"delayed due to customer service\" Huh? http://t.co/XlTV5z6sT1   \n",
       "98                                                       @united what about the poor customer service at checkin at Kansas KCI?!? That's it???   \n",
       "99                                                                                       @united except all of that delayed the flight anyway.   \n",
       "\n",
       "        BERT   ELECTRA    Vader DistilBERT   RoBERTa  \n",
       "0   negative  negative  neutral   negative  negative  \n",
       "1   negative  negative  neutral   negative  negative  \n",
       "2   negative  positive  neutral   negative  negative  \n",
       "3   negative  negative  neutral   negative  negative  \n",
       "4   negative  negative  neutral   negative  negative  \n",
       "..       ...       ...      ...        ...       ...  \n",
       "95  negative  negative  neutral   positive  negative  \n",
       "96  negative  negative  neutral   positive  negative  \n",
       "97  negative   neutral  neutral   negative  negative  \n",
       "98  negative  negative  neutral   negative  negative  \n",
       "99  negative  negative  neutral   negative  negative  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "a4082d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Vader</th>\n",
       "      <th>BERT</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>ELECTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1_Macro</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Neutral_Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Positive_Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Negative_Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sentiment  Vader  BERT  DistilBERT  RoBERTa  ELECTRA\n",
       "F1_Macro                       0.0    0.0   0.0         0.0      0.0      0.0\n",
       "F1_Macro_Neutral_Score         0.0    0.0   0.0         0.0      0.0      0.0\n",
       "F1_Macro_Positive_Score        0.0    0.0   0.0         0.0      0.0      0.0\n",
       "F1_Macro_Negative_Score        0.0    0.0   0.0         0.0      0.0      0.0"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "794949b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_Score.loc['F1_Macro']\n",
    "# f1_score(metricset.iloc[neutralset.index]['sentiment'], neutralset.Vader, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ef65bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_score(metricset.iloc[neutralset.index]['sentiment'], neutralset['BERT'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a0c53cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metricset.iloc[neutralset.index]['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "84807d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_Score['Vader'].loc['F1_Macro_Neutral_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "bb7b0c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tabulate_neutral_score(model,sentiment,metric):\n",
    "# #     print(\"Model: \", model, sentiment,metric)\n",
    "#     neutralset = metricset[metricset[model] == sentiment]\n",
    "# #     print(neutralset[model])\n",
    "#     Model_Score[model].loc['F1_Macro_Neutral_Score'] = f1_score(metricset.iloc[neutralset.index]['sentiment'], neutralset[model], average='macro')\n",
    "# #     f1_score(metricset.iloc[neutralset.index]['sentiment'], neutralset[model], average='macro')                                                                          \n",
    "# #     print(f1_score(metricset.iloc[neutralset.index]['sentiment'], neutralset[model], average='macro'))\n",
    "# #     Model_Score[model].loc['F1_Macro_Neutral_Score'] = f1_score(metricset['sentiment'], neutralset[model], average='macro')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d48fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b437d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabulate_neutral_score(model='Vader',senti='neutral',metric='F1_Macro_Neutral_Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "30f1566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_neutral_score(model,sentiment,metric):\n",
    "#     print(\"Model: \", model, sentiment,metric)\n",
    "    neutralset = metricset[metricset['sentiment'] == sentiment]\n",
    "#     print(neutralset)\n",
    "    Model_Score[model].loc['F1_Macro_Neutral_Score'] = f1_score(neutralset['sentiment'], neutralset[model], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "f48616de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_positive_score(model,sentiment,metric):\n",
    "#     print(\"Model: \", model, sentiment,metric)\n",
    "    positiveset = metricset[metricset['sentiment'] == sentiment]\n",
    "#     print(positiveset)\n",
    "    Model_Score[model].loc['F1_Macro_Positive_Score'] = f1_score(positiveset['sentiment'], positiveset[model], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "532714a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_negative_score(model,sentiment,metric):\n",
    "#     print(\"Model: \", model, sentiment,metric)\n",
    "    negativeset = metricset[metricset['sentiment'] == sentiment]\n",
    "#     print(negativeset)\n",
    "    Model_Score[model].loc['F1_Macro_Negative_Score'] = f1_score(negativeset['sentiment'], negativeset[model], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "9b07c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tabulate_positive_score(model,sentiment,metric):\n",
    "# #     print(\"Model: \", model, sentiment,metric)\n",
    "#     positiveset = metricset[metricset[model] == sentiment]\n",
    "# #     print(positiveset)\n",
    "#     Model_Score[model].loc['F1_Macro_Positive_Score'] = f1_score(metricset.iloc[positiveset.index]['sentiment'], positiveset[model], average='macro')\n",
    "# #     print(f1_score(metricset.iloc[positiveset.index]['sentiment'], positiveset[model], average='macro'))\n",
    "# #     Model_Score[model].loc['F1_Macro_Positive_Score'] = f1_score(positiveset['sentiment'], positiveset[model], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "bb7e932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tabulate_negative_score(model,sentiment,metric):\n",
    "# #     print(\"Model: \", model, sentiment,metric)\n",
    "#     negativeset = metricset[metricset[model] == sentiment]\n",
    "# #     print(negativeset)\n",
    "#     Model_Score[model].loc['F1_Macro_Negative_Score'] = f1_score(metricset.iloc[negativeset.index]['sentiment'], negativeset[model], average='macro')\n",
    "# #     Model_Score[model].loc['F1_Macro_Negative_Score'] = f1_score(negativeset['sentiment'], negativeset[model], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "94667c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutral_support_count(model, sentiment):\n",
    "    neutralset = metricset[metricset[model] == sentiment]\n",
    "    return neutralset[model].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "5ba88665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metricset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a36ee6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# support_series=[]\n",
    "# support_series.append(neutral_support_count(model=\"sentiment\", sentiment=\"neutral\"))\n",
    "# support_series.append(neutral_support_count(model=\"Vader\", sentiment=\"neutral\"))\n",
    "# support_series.append(neutral_support_count(model=\"BERT\", sentiment=\"neutral\"))\n",
    "# support_series.append(neutral_support_count(model=\"DistilBERT\", sentiment=\"neutral\"))\n",
    "# support_series.append(neutral_support_count(model=\"RoBERTa\", sentiment=\"neutral\"))\n",
    "# support_series.append(neutral_support_count(model=\"ELECTRA\", sentiment=\"neutral\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "e214f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# support_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "0ea5b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metricset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e345ff04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Vader</th>\n",
       "      <th>BERT</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>ELECTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1_Macro</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Neutral_Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Positive_Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Negative_Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sentiment  Vader  BERT  DistilBERT  RoBERTa  ELECTRA\n",
       "F1_Macro                       0.0    0.0   0.0         0.0      0.0      0.0\n",
       "F1_Macro_Neutral_Score         0.0    0.0   0.0         0.0      0.0      0.0\n",
       "F1_Macro_Positive_Score        0.0    0.0   0.0         0.0      0.0      0.0\n",
       "F1_Macro_Negative_Score        0.0    0.0   0.0         0.0      0.0      0.0"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "793d964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_Score['Grounding'].loc['F1_Macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d9b37972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_Score['Grounding'].loc['F1_Macro'] = f1_score(metricset['sentiment'], metricset['sentiment'], average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "817e7df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grounding</th>\n",
       "      <th>Vader</th>\n",
       "      <th>BERT</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>ELECTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1_Macro</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.240355</td>\n",
       "      <td>0.928849</td>\n",
       "      <td>0.504527</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.508014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Neutral_Score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Positive_Score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Negative_Score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.311688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Grounding     Vader      BERT  DistilBERT   RoBERTa  \\\n",
       "F1_Macro                       1.0  0.240355  0.928849    0.504527  0.300366   \n",
       "F1_Macro_Neutral_Score         1.0  0.466667  0.428571    0.000000  0.000000   \n",
       "F1_Macro_Positive_Score        1.0  0.333333  0.473684    0.473684  0.000000   \n",
       "F1_Macro_Negative_Score        1.0  0.008032  1.000000    0.474359  1.000000   \n",
       "\n",
       "                          ELECTRA  \n",
       "F1_Macro                 0.508014  \n",
       "F1_Macro_Neutral_Score   0.111111  \n",
       "F1_Macro_Positive_Score  0.222222  \n",
       "F1_Macro_Negative_Score  0.311688  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Score['sentiment'].loc['F1_Macro'] = f1_score(metricset['sentiment'], metricset['sentiment'], average='macro')\n",
    "Model_Score['Vader'].loc['F1_Macro'] = f1_score(metricset.sentiment, metricset.Vader, average='macro')\n",
    "Model_Score['BERT'].loc['F1_Macro'] = f1_score(metricset.sentiment, metricset.BERT, average='macro')\n",
    "Model_Score['DistilBERT'].loc['F1_Macro'] = f1_score(metricset.sentiment, metricset.DistilBERT, average='macro')\n",
    "Model_Score['RoBERTa'].loc['F1_Macro'] = f1_score(metricset.sentiment, metricset.RoBERTa, average='macro')\n",
    "Model_Score['ELECTRA'].loc['F1_Macro'] = f1_score(metricset.sentiment, metricset.ELECTRA, average='macro')\n",
    "\n",
    "tabulate_neutral_score(model=\"sentiment\", sentiment=\"neutral\", metric=\"F1_Macro_Neutral_Score\")\n",
    "tabulate_neutral_score(model=\"Vader\", sentiment=\"neutral\", metric=\"F1_Macro_Neutral_Score\")\n",
    "tabulate_neutral_score(model=\"BERT\", sentiment=\"neutral\", metric=\"F1_Macro_Neutral_Score\")\n",
    "tabulate_neutral_score(model=\"DistilBERT\", sentiment=\"neutral\", metric=\"F1_Macro_Neutral_Score\")\n",
    "tabulate_neutral_score(model=\"RoBERTa\", sentiment=\"neutral\", metric=\"F1_Macro_Neutral_Score\")\n",
    "tabulate_neutral_score(model=\"ELECTRA\", sentiment=\"neutral\", metric=\"F1_Macro_Neutral_Score\")\n",
    "\n",
    "tabulate_positive_score(model=\"sentiment\", sentiment=\"positive\", metric=\"F1_Macro_Positive_Score\")\n",
    "tabulate_positive_score(model=\"Vader\", sentiment=\"positive\", metric=\"F1_Macro_Positive_Score\")\n",
    "tabulate_positive_score(model=\"BERT\", sentiment=\"positive\", metric=\"F1_Macro_Positive_Score\")\n",
    "tabulate_positive_score(model=\"DistilBERT\", sentiment=\"positive\", metric=\"F1_Macro_Positive_Score\")\n",
    "tabulate_positive_score(model=\"RoBERTa\", sentiment=\"positive\", metric=\"F1_Macro_Positive_Score\")\n",
    "tabulate_positive_score(model=\"ELECTRA\", sentiment=\"positive\", metric=\"F1_Macro_Positive_Score\")\n",
    "\n",
    "tabulate_negative_score(model=\"sentiment\", sentiment=\"negative\", metric=\"F1_Macro_Negative_Score\")\n",
    "tabulate_negative_score(model=\"Vader\", sentiment=\"negative\", metric=\"F1_Macro_Negative_Score\")\n",
    "tabulate_negative_score(model=\"BERT\", sentiment=\"negative\", metric=\"F1_Macro_Negative_Score\")\n",
    "tabulate_negative_score(model=\"DistilBERT\", sentiment=\"negative\", metric=\"F1_Macro_Negative_Score\")\n",
    "tabulate_negative_score(model=\"RoBERTa\", sentiment=\"negative\", metric=\"F1_Macro_Negative_Score\")\n",
    "tabulate_negative_score(model=\"ELECTRA\", sentiment=\"negative\", metric=\"F1_Macro_Negative_Score\")\n",
    "\n",
    "Model_Score = Model_Score.fillna(0)\n",
    "Model_Score.rename(columns = {'sentiment':'Grounding'}, inplace = True)\n",
    "Model_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "61a3954a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.lineplot(data=Model_Score.loc['F1_Macro'], label='F1 Macro')\n",
    "ax.set_ylabel ('Score', fontsize = 10)\n",
    "ax = sns.lineplot(data=Model_Score.loc['F1_Macro_Neutral_Score'], label='F1_Macro_Neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "0108f01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xticks(rotation=90)\n",
    "ax = sns.lineplot(data=Model_Score['Grounding'], label='Score')\n",
    "ax = sns.lineplot(data=Model_Score['Vader'], label='Vader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "2588fac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xticks(rotation=90)\n",
    "ax = sns.lineplot(data=Model_Score['Grounding'], label='Grounding')\n",
    "# ax = sns.lineplot(data=Model_Score['Vader'], label='Vader')\n",
    "ax = sns.lineplot(data=Model_Score['BERT'], label='BERT')\n",
    "ax = sns.lineplot(data=Model_Score['DistilBERT'], label='DistilBERT')\n",
    "ax = sns.lineplot(data=Model_Score['RoBERTa'], label='RoBERTa')\n",
    "ax = sns.lineplot(data=Model_Score['ELECTRA'], label='ELECTRA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6574ec49",
   "metadata": {},
   "source": [
    "### Neutral Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "3c03cd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>BERT</th>\n",
       "      <th>ELECTRA</th>\n",
       "      <th>Vader</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united On top of that I paid for 1st class and my wife got stuck in coach.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united Ph the pat answers are BS. After I was denied boarding it sat at the gate until 9:05! Your employees totally suck.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@United Over the last week, United has provided me with the worst customer service experience of my life. Disgusting. #united</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united 24 hrs since flight landed and ZERO info on my missing bag? rough ETA would be hugely helpful + restore some confidence</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united big surprise #nogate waiting for our plane. Same fucken issues everything I fly you. #fail #worstairlineever</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united You're trying to solve problem of your own making. Charging for checked luggage forces checking at gate. Brilliant.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united we've been waiting 45 min for a gate at SFO... Yet so many of them are free.  Your excellence in operational efficiency is showing</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>negative</td>\n",
       "      <td>@United \"delayed due to customer service\" Huh? http://t.co/XlTV5z6sT1</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united what about the poor customer service at checkin at Kansas KCI?!? That's it???</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united except all of that delayed the flight anyway.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0   negative   \n",
       "1   negative   \n",
       "2   negative   \n",
       "3   negative   \n",
       "4   negative   \n",
       "..       ...   \n",
       "95  negative   \n",
       "96  negative   \n",
       "97  negative   \n",
       "98  negative   \n",
       "99  negative   \n",
       "\n",
       "                                                                                                                                          text  \\\n",
       "0                                                                  @united On top of that I paid for 1st class and my wife got stuck in coach.   \n",
       "1                   @united Ph the pat answers are BS. After I was denied boarding it sat at the gate until 9:05! Your employees totally suck.   \n",
       "2                @United Over the last week, United has provided me with the worst customer service experience of my life. Disgusting. #united   \n",
       "3              @united 24 hrs since flight landed and ZERO info on my missing bag? rough ETA would be hugely helpful + restore some confidence   \n",
       "4                         @united big surprise #nogate waiting for our plane. Same fucken issues everything I fly you. #fail #worstairlineever   \n",
       "..                                                                                                                                         ...   \n",
       "95                 @united You're trying to solve problem of your own making. Charging for checked luggage forces checking at gate. Brilliant.   \n",
       "96  @united we've been waiting 45 min for a gate at SFO... Yet so many of them are free.  Your excellence in operational efficiency is showing   \n",
       "97                                                                       @United \"delayed due to customer service\" Huh? http://t.co/XlTV5z6sT1   \n",
       "98                                                       @united what about the poor customer service at checkin at Kansas KCI?!? That's it???   \n",
       "99                                                                                       @united except all of that delayed the flight anyway.   \n",
       "\n",
       "        BERT   ELECTRA    Vader DistilBERT   RoBERTa  \n",
       "0   negative  negative  neutral   negative  negative  \n",
       "1   negative  negative  neutral   negative  negative  \n",
       "2   negative  positive  neutral   negative  negative  \n",
       "3   negative  negative  neutral   negative  negative  \n",
       "4   negative  negative  neutral   negative  negative  \n",
       "..       ...       ...      ...        ...       ...  \n",
       "95  negative  negative  neutral   positive  negative  \n",
       "96  negative  negative  neutral   positive  negative  \n",
       "97  negative   neutral  neutral   negative  negative  \n",
       "98  negative  negative  neutral   negative  negative  \n",
       "99  negative  negative  neutral   negative  negative  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c8d64418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt \n",
    "sns.set(rc={\"figure.figsize\":(10, 4)})\n",
    "f, (ax1, ax2,ax3,ax4,ax5,ax6) = plt.subplots(1, 6, sharey=True)\n",
    "# ax1.set_ylabel ('Support', fontsize = 10)\n",
    "ax2.set_ylabel ('Polarization %', fontsize = 10)\n",
    "subplot1 = sns.countplot(metricset.sentiment, label='Support',ax=ax1,order = metricset['sentiment'].value_counts().index)\n",
    "subplot2 = sns.countplot(metricset.Vader, label='Support',ax=ax2,order = metricset['sentiment'].value_counts().index)\n",
    "subplot3 = sns.countplot(metricset.BERT, label='Support',ax=ax3,order = metricset['sentiment'].value_counts().index)\n",
    "subplot4 = sns.countplot(metricset.DistilBERT, label='Support',ax=ax4,order = metricset['sentiment'].value_counts().index)\n",
    "subplot5 = sns.countplot(metricset.RoBERTa, label='Support',ax=ax5,order = metricset['sentiment'].value_counts().index)\n",
    "subplot6 = sns.countplot(metricset.ELECTRA, label='Support',ax=ax6,order = metricset['sentiment'].value_counts().index)\n",
    "subplot1.set_xticklabels(labels=[\"negative\", \"neutral\", \"positive\"],rotation=90)\n",
    "subplot2.set_xticklabels(labels=[\"negative\", \"neutral\", \"positive\"],rotation=90)\n",
    "subplot3.set_xticklabels(labels=[\"negative\", \"neutral\", \"positive\"],rotation=90)\n",
    "subplot4.set_xticklabels(labels=[\"negative\", \"neutral\", \"positive\"],rotation=90)\n",
    "subplot5.set_xticklabels(labels=[\"negative\", \"neutral\", \"positive\"],rotation=90)\n",
    "subplot6.set_xticklabels(labels=[\"negative\", \"neutral\", \"positive\"],rotation=90)\n",
    "ax2.set_ylabel ('', fontsize = 10)\n",
    "ax3.set_ylabel ('', fontsize = 10)\n",
    "ax4.set_ylabel ('', fontsize = 10)\n",
    "ax5.set_ylabel ('', fontsize = 10)\n",
    "ax6.set_ylabel ('', fontsize = 10)\n",
    "# ax4.set_ylabel ('Support', fontsize = 10)\n",
    "ax1.set_ylabel ('Polarization %', fontsize = 12)\n",
    "\n",
    "vals = ax1.get_yticks()\n",
    "# print(vals)\n",
    "# ax1.set_yticklabels(['{:,%}'.format(x/17) for x in vals])\n",
    "# ax1.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y))) \n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(100*x/vals[-2]) for x in plt.gca().get_yticks()]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4c4d3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Polarity_Tabulation = pd.DataFrame(\n",
    "    {'sentiment': [\"0.0\",\"0.0\",\"0.0\"],\n",
    "     'Vader': [\"0.0\",\"0.0\",\"0.0\"],\n",
    "     'BERT': [\"0.0\",\"0.0\",\"0.0\",],\n",
    "     'DistilBERT': [\"0.0\",\"0.0\",\"0.0\",],\n",
    "     'RoBERTa': [\"0.0\",\"0.0\",\"0.0\",],\n",
    "     'ELECTRA': [\"0.0\",\"0.0\",\"0.0\",]\n",
    "    },\n",
    "    index=['negative(%)', 'neutral(%)','positive(%)']\n",
    ")\n",
    "Polarity_Tabulation = Polarity_Tabulation.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "bc1ff74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metricset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "966ea55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_df = metricset\n",
    "percentage_table = per_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "d780000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Percentage_Tabulation = pd.DataFrame(\n",
    "    {'sentiment': [\"0.0\",\"0.0\",\"0.0\"],\n",
    "     'Vader': [\"0.0\",\"0.0\",\"0.0\"],\n",
    "     'BERT': [\"0.0\",\"0.0\",\"0.0\",],\n",
    "     'DistilBERT': [\"0.0\",\"0.0\",\"0.0\",],\n",
    "     'RoBERTa': [\"0.0\",\"0.0\",\"0.0\",],\n",
    "     'ELECTRA': [\"0.0\",\"0.0\",\"0.0\",]\n",
    "    },\n",
    "    index=['negative(%)', 'neutral(%)','positive(%)']\n",
    ")\n",
    "Percentage_Tabulation = Percentage_Tabulation.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "8a9f9430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Vader</th>\n",
       "      <th>BERT</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>ELECTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative(%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral(%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive(%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentiment  Vader  BERT  DistilBERT  RoBERTa  ELECTRA\n",
       "negative(%)        0.0    0.0   0.0         0.0      0.0      0.0\n",
       "neutral(%)         0.0    0.0   0.0         0.0      0.0      0.0\n",
       "positive(%)        0.0    0.0   0.0         0.0      0.0      0.0"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Percentage_Tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "2abca60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>BERT</th>\n",
       "      <th>ELECTRA</th>\n",
       "      <th>Vader</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united On top of that I paid for 1st class and my wife got stuck in coach.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united Ph the pat answers are BS. After I was denied boarding it sat at the gate until 9:05! Your employees totally suck.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@United Over the last week, United has provided me with the worst customer service experience of my life. Disgusting. #united</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united 24 hrs since flight landed and ZERO info on my missing bag? rough ETA would be hugely helpful + restore some confidence</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united big surprise #nogate waiting for our plane. Same fucken issues everything I fly you. #fail #worstairlineever</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united You're trying to solve problem of your own making. Charging for checked luggage forces checking at gate. Brilliant.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united we've been waiting 45 min for a gate at SFO... Yet so many of them are free.  Your excellence in operational efficiency is showing</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>negative</td>\n",
       "      <td>@United \"delayed due to customer service\" Huh? http://t.co/XlTV5z6sT1</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united what about the poor customer service at checkin at Kansas KCI?!? That's it???</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united except all of that delayed the flight anyway.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0   negative   \n",
       "1   negative   \n",
       "2   negative   \n",
       "3   negative   \n",
       "4   negative   \n",
       "..       ...   \n",
       "95  negative   \n",
       "96  negative   \n",
       "97  negative   \n",
       "98  negative   \n",
       "99  negative   \n",
       "\n",
       "                                                                                                                                          text  \\\n",
       "0                                                                  @united On top of that I paid for 1st class and my wife got stuck in coach.   \n",
       "1                   @united Ph the pat answers are BS. After I was denied boarding it sat at the gate until 9:05! Your employees totally suck.   \n",
       "2                @United Over the last week, United has provided me with the worst customer service experience of my life. Disgusting. #united   \n",
       "3              @united 24 hrs since flight landed and ZERO info on my missing bag? rough ETA would be hugely helpful + restore some confidence   \n",
       "4                         @united big surprise #nogate waiting for our plane. Same fucken issues everything I fly you. #fail #worstairlineever   \n",
       "..                                                                                                                                         ...   \n",
       "95                 @united You're trying to solve problem of your own making. Charging for checked luggage forces checking at gate. Brilliant.   \n",
       "96  @united we've been waiting 45 min for a gate at SFO... Yet so many of them are free.  Your excellence in operational efficiency is showing   \n",
       "97                                                                       @United \"delayed due to customer service\" Huh? http://t.co/XlTV5z6sT1   \n",
       "98                                                       @united what about the poor customer service at checkin at Kansas KCI?!? That's it???   \n",
       "99                                                                                       @united except all of that delayed the flight anyway.   \n",
       "\n",
       "        BERT   ELECTRA    Vader DistilBERT   RoBERTa  \n",
       "0   negative  negative  neutral   negative  negative  \n",
       "1   negative  negative  neutral   negative  negative  \n",
       "2   negative  positive  neutral   negative  negative  \n",
       "3   negative  negative  neutral   negative  negative  \n",
       "4   negative  negative  neutral   negative  negative  \n",
       "..       ...       ...      ...        ...       ...  \n",
       "95  negative  negative  neutral   positive  negative  \n",
       "96  negative  negative  neutral   positive  negative  \n",
       "97  negative   neutral  neutral   negative  negative  \n",
       "98  negative  negative  neutral   negative  negative  \n",
       "99  negative  negative  neutral   negative  negative  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "6b7e22f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # label = \"DistilBERT\"\n",
    "label = \"sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "c3e2b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage_table = metricset[label].value_counts()/metricset[label].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "8e088e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_table = per_df[label].value_counts()/metricset[label].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "548c7795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.82\n",
       "positive    0.10\n",
       "neutral     0.08\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "34b0c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment= sentiment+\"(%)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "7bdfd886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_tabulate(per_df, label, sentiment):\n",
    "    try :\n",
    "        sentiment_tag = sentiment+\"(%)\"\n",
    "        percentage_table = per_df[label].value_counts()/metricset[label].count()\n",
    "        Percentage_Tabulation[label].loc[sentiment_tag] = round(percentage_table.loc[sentiment],2)*100\n",
    "    except Exception:\n",
    "        pass\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "9ac8697d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.0"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(percentage_table.loc[\"negative\"],2)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "2553f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_tabulate(percentage_table, label=\"sentiment\", sentiment=\"negative\")\n",
    "func_tabulate(percentage_table, label=\"sentiment\", sentiment=\"neutral\")\n",
    "func_tabulate(percentage_table, label=\"sentiment\", sentiment=\"positive\")\n",
    "func_tabulate(percentage_table, label=\"Vader\", sentiment=\"negative\")\n",
    "func_tabulate(percentage_table, label=\"Vader\", sentiment=\"neutral\")\n",
    "func_tabulate(percentage_table, label=\"Vader\", sentiment=\"positive\")\n",
    "func_tabulate(percentage_table, label=\"BERT\", sentiment=\"negative\")\n",
    "func_tabulate(percentage_table, label=\"BERT\", sentiment=\"neutral\")\n",
    "func_tabulate(percentage_table, label=\"BERT\", sentiment=\"positive\")\n",
    "func_tabulate(percentage_table, label=\"DistilBERT\", sentiment=\"negative\")\n",
    "func_tabulate(percentage_table, label=\"DistilBERT\", sentiment=\"neutral\")\n",
    "func_tabulate(percentage_table, label=\"DistilBERT\", sentiment=\"positive\")\n",
    "func_tabulate(percentage_table, label=\"RoBERTa\", sentiment=\"negative\")\n",
    "func_tabulate(percentage_table, label=\"RoBERTa\", sentiment=\"neutral\")\n",
    "func_tabulate(percentage_table, label=\"RoBERTa\", sentiment=\"positive\")\n",
    "func_tabulate(percentage_table, label=\"ELECTRA\", sentiment=\"negative\")\n",
    "func_tabulate(percentage_table, label=\"ELECTRA\", sentiment=\"neutral\")\n",
    "func_tabulate(percentage_table, label=\"ELECTRA\", sentiment=\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5ef64c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Vader</th>\n",
       "      <th>BERT</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>ELECTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative(%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral(%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive(%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentiment  Vader  BERT  DistilBERT  RoBERTa  ELECTRA\n",
       "negative(%)        0.0    0.0   0.0         0.0      0.0      0.0\n",
       "neutral(%)         0.0    0.0   0.0         0.0      0.0      0.0\n",
       "positive(%)        0.0    0.0   0.0         0.0      0.0      0.0"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Percentage_Tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "2863daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try :\n",
    "#     Percentage_Tabulation[label].loc['neutral(%)'] = round(percentage_table.loc['neutral'],2)*100\n",
    "# except Exception:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "ac8ffd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try :\n",
    "#     Percentage_Tabulation[label].loc['positive(%)'] = round(percentage_table.loc['positive'],2)*100\n",
    "# except Exception:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "6b083007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.82\n",
       "positive    0.10\n",
       "neutral     0.08\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "effd389b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.41\n",
       "positive    0.05\n",
       "neutral     0.04\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_table/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b027b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round(percentage_table[label],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "55e9b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage_table[label] = round(percentage_table[label],2)\n",
    "# percentage_table[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "7d6c7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_table['negative']=0.0\n",
    "percentage_table['neutral']=0.0\n",
    "percentage_table['positive']=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1a6acf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.82\n",
       "positive    0.10\n",
       "neutral     0.08\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_df[label].value_counts()/metricset[label].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "338bcb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_df(df,label):\n",
    "#     print(per_df)\n",
    "#     print(label)\n",
    "    per_table = pd.DataFrame()\n",
    "#     per_table['negative']=0\n",
    "#     per_table['neutral']=0\n",
    "#     per_table['positive']=0\n",
    "    try:\n",
    "        if label in df.columns:\n",
    "#             print(label)\n",
    "            per_table = df[label].value_counts()/metricset[label].count()\n",
    "            per_table[label] = round(per_table,2)*100\n",
    "#             temp =  per_table[label]\n",
    "            if \"neutral\" not in per_table.index:\n",
    "#                 print(\"neutral does not exist\")\n",
    "                per_table[label]['neutral']=0\n",
    "#                 print (per_table)\n",
    "            elif \"positive\" not in per_table.index:\n",
    "#                 print(\"positive does not exist\")\n",
    "                per_table[label]['positive']=0\n",
    "            elif \"negative\" not in per_table.index:\n",
    "#                 print(\"negative does not exist\")\n",
    "                per_table[label]['negative']=0\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "#             print(per_table)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "#         print(per_table[label])\n",
    "        return per_table[label]  \n",
    "    except Exception:     \n",
    "        pass   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "8a5cc75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    80.0\n",
       "positive    20.0\n",
       "neutral      0.0\n",
       "Name: DistilBERT, dtype: float64"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_df(per_df,\"DistilBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d473dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = per_df['DistilBERT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "ef5a8b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral1 does not exist\n"
     ]
    }
   ],
   "source": [
    "if \"neutral1\" not in a1.index:\n",
    "    print(\"neutral1 does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "80e11fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1['neutral']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "c0e76199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    80\n",
       "positive    20\n",
       "neutral      0\n",
       "Name: DistilBERT, dtype: int64"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "7e502370",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf= percentage_df(per_df,\"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "6af9ee43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    82.0\n",
       "positive    10.0\n",
       "neutral      8.0\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "080a0b05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    Polarity_Tabulation['sentiment'].loc['negative(%)'] = percentage_df(per_df,\"sentiment\").loc['negative']\n",
    "    Polarity_Tabulation['sentiment'].loc['neutral(%)'] = percentage_df(per_df,\"sentiment\").loc['neutral']\n",
    "    Polarity_Tabulation['sentiment'].loc['positive(%)'] = percentage_df(per_df,\"sentiment\").loc['positive']\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9df4d91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Vader</th>\n",
       "      <th>BERT</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>ELECTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative(%)</th>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral(%)</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive(%)</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentiment  Vader  BERT  DistilBERT  RoBERTa  ELECTRA\n",
       "negative(%)       82.0    0.0   0.0         0.0      0.0      0.0\n",
       "neutral(%)         8.0    0.0   0.0         0.0      0.0      0.0\n",
       "positive(%)       10.0    0.0   0.0         0.0      0.0      0.0"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Polarity_Tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "37448fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Polarity_Tabulation['Vader'].loc['negative(%)'] = percentage_df(per_df,\"Vader\").loc['negative']\n",
    "    Polarity_Tabulation['Vader'].loc['neutral(%)'] = percentage_df(per_df,\"Vader\").loc['neutral']\n",
    "    Polarity_Tabulation['Vader'].loc['positive(%)'] = percentage_df(per_df,\"Vader\").loc['positive']\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "68c965fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Vader</th>\n",
       "      <th>BERT</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>ELECTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative(%)</th>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral(%)</th>\n",
       "      <td>8.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive(%)</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentiment  Vader  BERT  DistilBERT  RoBERTa  ELECTRA\n",
       "negative(%)       82.0    1.0   0.0         0.0      0.0      0.0\n",
       "neutral(%)         8.0   91.0   0.0         0.0      0.0      0.0\n",
       "positive(%)       10.0    8.0   0.0         0.0      0.0      0.0"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Polarity_Tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "a1e44493",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Polarity_Tabulation['BERT'].loc['negative(%)'] = percentage_df(per_df,\"BERT\").loc['negative']\n",
    "    Polarity_Tabulation['BERT'].loc['neutral(%)'] = percentage_df(per_df,\"BERT\").loc['neutral']\n",
    "    Polarity_Tabulation['BERT'].loc['positive(%)'] = percentage_df(per_df,\"BERT\").loc['positive']\n",
    "\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "9d8bf5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.0"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_df(per_df,\"BERT\").loc['negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "9bd22691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Vader</th>\n",
       "      <th>BERT</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>ELECTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative(%)</th>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral(%)</th>\n",
       "      <td>8.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive(%)</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentiment  Vader  BERT  DistilBERT  RoBERTa  ELECTRA\n",
       "negative(%)       82.0    1.0  85.0         0.0      0.0      0.0\n",
       "neutral(%)         8.0   91.0   6.0         0.0      0.0      0.0\n",
       "positive(%)       10.0    8.0   9.0         0.0      0.0      0.0"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Polarity_Tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "665a95d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Polarity_Tabulation['DistilBERT'].loc['negative(%)'] = percentage_df(per_df,\"DistilBERT\").loc['negative']\n",
    "    Polarity_Tabulation['DistilBERT'].loc['neutral(%)'] = percentage_df(per_df,\"DistilBERT\").loc['neutral']\n",
    "    Polarity_Tabulation['DistilBERT'].loc['positive(%)'] = percentage_df(per_df,\"DistilBERT\").loc['positive']\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "f17212fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Polarity_Tabulation['DistilBERT'].loc['neutral(%)'] = percentage_df(per_df,\"DistilBERT\").loc['neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "3fd8e651",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grounding</th>\n",
       "      <th>Vader</th>\n",
       "      <th>BERT</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>ELECTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative(%)</th>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral(%)</th>\n",
       "      <td>8.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive(%)</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Grounding  Vader  BERT  DistilBERT  RoBERTa  ELECTRA\n",
       "negative(%)       82.0    1.0  85.0        80.0      0.0      0.0\n",
       "neutral(%)         8.0   91.0   6.0         0.0      0.0      0.0\n",
       "positive(%)       10.0    8.0   9.0        20.0      0.0      0.0"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Polarity_Tabulation.rename(columns = {'sentiment':'Grounding'}, inplace = True)\n",
    "Polarity_Tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "6b3eb3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Polarity_Tabulation['RoBERTa'].loc['negative(%)'] = percentage_df(per_df,\"RoBERTa\").loc['negative']\n",
    "    Polarity_Tabulation['RoBERTa'].loc['neutral(%)'] = percentage_df(per_df,\"RoBERTa\").loc['neutral']\n",
    "    Polarity_Tabulation['RoBERTa'].loc['positive(%)'] = percentage_df(per_df,\"RoBERTa\").loc['positive']\n",
    "    \n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b14c4f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grounding</th>\n",
       "      <th>Vader</th>\n",
       "      <th>BERT</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>ELECTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative(%)</th>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral(%)</th>\n",
       "      <td>8.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive(%)</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Grounding  Vader  BERT  DistilBERT  RoBERTa  ELECTRA\n",
       "negative(%)       82.0    1.0  85.0        80.0    100.0      0.0\n",
       "neutral(%)         8.0   91.0   6.0         0.0      0.0      0.0\n",
       "positive(%)       10.0    8.0   9.0        20.0      0.0      0.0"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Polarity_Tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "20643479",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Polarity_Tabulation['ELECTRA'].loc['negative(%)'] = percentage_df(per_df,\"ELECTRA\").loc['negative']\n",
    "    Polarity_Tabulation['ELECTRA'].loc['neutral(%)'] = percentage_df(per_df,\"ELECTRA\").loc['neutral']\n",
    "    Polarity_Tabulation['ELECTRA'].loc['positive(%)'] = percentage_df(per_df,\"ELECTRA\").loc['positive']\n",
    "    \n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "4f0eef86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grounding</th>\n",
       "      <th>Vader</th>\n",
       "      <th>BERT</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>ELECTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative(%)</th>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral(%)</th>\n",
       "      <td>8.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive(%)</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Grounding  Vader  BERT  DistilBERT  RoBERTa  ELECTRA\n",
       "negative(%)       82.0    1.0  85.0        80.0    100.0     83.0\n",
       "neutral(%)         8.0   91.0   6.0         0.0      0.0      8.0\n",
       "positive(%)       10.0    8.0   9.0        20.0      0.0      9.0"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Polarity_Tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "27f8409d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     91.0\n",
       "positive     8.0\n",
       "negative     1.0\n",
       "Name: Vader, dtype: float64"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_df(per_df,\"Vader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "734422ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_Polarity = percentage_df(per_df,\"BERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "4bd2ad0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    85.0\n",
       "positive     9.0\n",
       "neutral      6.0\n",
       "Name: BERT, dtype: float64"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "080703e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage_table = percentage_df['Grounding'].value_counts()/metricset['Grounding'].count()\n",
    "# percentage_table['Grounding_percentage'] = round(percentage_table,2)*100\n",
    "# percentage_table['Grounding_percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "44efa6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, (ax4, ax5) = plt.subplots(1, 2, sharey=True)\n",
    "# ax4.set_ylabel ('Support', fontsize = 10)\n",
    "# ax5.set_ylabel ('Polarization Count', fontsize = 10)\n",
    "# subplot1 = sns.countplot(metricset.DistilBERT, label='Support',ax=ax4,order = metricset['Grounding'].value_counts().index)\n",
    "# subplot2 = sns.countplot(metricset.ELECTRA, label='Support',ax=ax5,order = metricset['Grounding'].value_counts().index)\n",
    "# subplot1.set_xticklabels(labels=[\"negative\", \"neutral\", \"positive\"],rotation=30)\n",
    "# subplot2.set_xticklabels(labels=[\"negative\", \"neutral\", \"positive\"],rotation=30)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "68e8344a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.xticks(rotation=90)\n",
    "ax = sns.lineplot(data=Model_Score['Grounding'], label='Grounding')\n",
    "ax.set_ylabel ('Score', fontsize = 10)\n",
    "ax.set_xticklabels(labels=[\"F1 Macro\", \"F1 Macro neutral\", \"F1 Macro positive\", \"F1 Macro negative\"],rotation=30)\n",
    "ax = sns.lineplot(data=Model_Score['DistilBERT'], label='DistilBERT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "1c054fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.xticks(rotation=90)\n",
    "sns.lineplot(data=Model_Score['Grounding'], label='Grounding')\n",
    "ax.set_ylabel ('Score', fontsize = 10)\n",
    "ax.set_xticklabels(labels=[\"F1 Macro\", \"F1 Macro neutral\", \"F1 Macro positive\", \"F1 Macro negative\"],rotation=30)\n",
    "ax = sns.lineplot(data=Model_Score['BERT'], label='Vader')\n",
    "ax.set_ylabel ('Score', fontsize = 10)\n",
    "ax = sns.lineplot(data=Model_Score['ELECTRA'], label='ELECTRA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "b6b71f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.xticks(rotation=90)\n",
    "sns.set(font_scale=1)\n",
    "ax = sns.lineplot(data=Model_Score['Grounding'], label='Grounding')\n",
    "ax.set_ylabel ('Score', fontsize = 12)\n",
    "\n",
    "ax.set_xticklabels(labels=[\"F1 Macro\", \"F1 Macro neutral\", \"F1 Macro positive\", \"F1 Macro negative\"],rotation=30)\n",
    "ax = sns.lineplot(data=Model_Score['ELECTRA'], label='ELECTRA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "2aa5b9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grounding</th>\n",
       "      <th>Vader</th>\n",
       "      <th>BERT</th>\n",
       "      <th>DistilBERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>ELECTRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1_Macro</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.240355</td>\n",
       "      <td>0.928849</td>\n",
       "      <td>0.504527</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.508014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Neutral_Score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Positive_Score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Macro_Negative_Score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.311688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Grounding     Vader      BERT  DistilBERT   RoBERTa  \\\n",
       "F1_Macro                       1.0  0.240355  0.928849    0.504527  0.300366   \n",
       "F1_Macro_Neutral_Score         1.0  0.466667  0.428571    0.000000  0.000000   \n",
       "F1_Macro_Positive_Score        1.0  0.333333  0.473684    0.473684  0.000000   \n",
       "F1_Macro_Negative_Score        1.0  0.008032  1.000000    0.474359  1.000000   \n",
       "\n",
       "                          ELECTRA  \n",
       "F1_Macro                 0.508014  \n",
       "F1_Macro_Neutral_Score   0.111111  \n",
       "F1_Macro_Positive_Score  0.222222  \n",
       "F1_Macro_Negative_Score  0.311688  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "8d4aec34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt = sns.lineplot(data=Model_Score.loc['F1_Macro'], label='F1 Macro')\n",
    "plt = sns.lineplot(data=Model_Score.loc['F1_Macro_Neutral_Score'], label='F1_Macro_Neutral')\n",
    "plt = sns.lineplot(data=Model_Score.loc['F1_Macro_Positive_Score'],label='F1_Macro_Positive')\n",
    "plt = sns.lineplot(data=Model_Score.loc['F1_Macro_Negative_Score'],label='F1_Macro_Negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a765bf17",
   "metadata": {},
   "source": [
    "## Business Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "84792800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If positive : Print \"you are happy with our service\"\n",
    "#                  Retweet (Customer Campaign)\n",
    "# if negative : Print \"i'm sorry you feel this way\"\n",
    "#                    Direct_Message (Customer Service_Ticket)\n",
    "# if neutral : Print \"\" exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "e6c8287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_tweet = \"My flight is delayed, I need a good explanation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "d001776b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.161, 'neu': 0.593, 'pos': 0.246, 'compound': 0.25}\n"
     ]
    }
   ],
   "source": [
    "score=sa.polarity_scores(customer_tweet)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "3db1f138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summary_text = summarizer(customer_tweet, max_length=50, min_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "83d19a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_summary = str(summary_text[0]).split(\"\\\"\")[1]\n",
    "# print(tweet_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "c34b046e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# score=sa.polarity_scores(tweet_summary)\n",
    "# print(score.get('neg'))\n",
    "# print(score.get('neu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "e73af2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_1=sa.polarity_scores(customer_tweet)\n",
    "idx_customer_tweet = np.argmax([score_1.get('neg'),score_1.get('neu'),score_1.get('pos')],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9337708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_2=sa.polarity_scores(tweet_summary)\n",
    "# idx_tweet_summary = np.argmax([score_2.get('neg'),score_2.get('neu'),score_2.get('pos')],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01575b2b",
   "metadata": {},
   "source": [
    "## Sentiment Contradictions & Differentiated Response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "c771b7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Tweet:  My flight is delayed, I need a good explanation\n",
      "Bot:(Neutral Sentiment)  --no response--\n"
     ]
    }
   ],
   "source": [
    "print(Customer_Service_Business_Rule(customer_tweet,idx_customer_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "12d7dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Customer_Service_Business_Rule_Transformer(tweet_summary,idx_tweet_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "75306cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_tweet = \"My flight is delayed, what the fcuk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "23a076b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\228e83e1ade2247aebc5f0725e330fa58dedee3d9eec36c9249f25084a946130.1aece0680a18a95d51d6e1a5f83631412da37b87db65380c52052161354505ba\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\228e83e1ade2247aebc5f0725e330fa58dedee3d9eec36c9249f25084a946130.1aece0680a18a95d51d6e1a5f83631412da37b87db65380c52052161354505ba\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\8fda88182b287ca423f06cae23d4c4701aaba057b65b3a691930de41e6537b3b.f135db3906a2e0c1f328a5920119f906cfb27b985cb0bfe7ef94434bdb31d031\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at siebert/sentiment-roberta-large-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\228e83e1ade2247aebc5f0725e330fa58dedee3d9eec36c9249f25084a946130.1aece0680a18a95d51d6e1a5f83631412da37b87db65380c52052161354505ba\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/vocab.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\b522c6365937d6f39045d31ba715daafd39604f04b745f9d3d5cd622ecd74408.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/merges.txt from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\a1fbb0cbc048b898b9adb0aa928b6bde50f393786ec91ffe195736820c42b02f.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/special_tokens_map.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\e7bd01a8669e2d76258ba5ab711ba48da69b2dfc573c7b02566c0e73bd4583f4.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n",
      "loading file https://huggingface.co/siebert/sentiment-roberta-large-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\pksk3/.cache\\huggingface\\transformers\\9f284be68d0cfa5298eea908fc7f51cc7e0b01c7aaf2eba99c70d938b169bfe8.ba4a40df74471cdc82cd580af48bbbcfd25e9095a9d4bb296f711f3af7e2619e\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"sentiment-analysis\", model=model_name)\n",
    "sentiment_dict = summarizer(customer_tweet, max_length=50, min_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "73ec7691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9994683861732483}]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "34430e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_3=sa.polarity_scores(customer_tweet)\n",
    "idx_customer_tweet = np.argmax([score_3.get('neg'),score_3.get('neu'),score_3.get('pos')],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "7c5c6423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.519, 'neu': 0.481, 'pos': 0.0, 'compound': -0.6597}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "e7b1462a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_customer_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "8319b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_4=sa.polarity_scores(summary_text)\n",
    "# idx_tweet_summary = np.argmax([score_4.get('neg'),score_4.get('neu'),score_4.get('pos')],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "03bbf0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Tweet:  My flight is delayed, what the fuck\n",
      "Bot (Negative Sentiment): I'm sorry you feel this way\n"
     ]
    }
   ],
   "source": [
    "print(Customer_Service_Business_Rule(customer_tweet,idx_customer_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "df8d3d2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(Customer_Service_Business_Rule_Transformer(tweet_summary,idx_tweet_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "476bb705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=-0.4, subjectivity=0.6)\n"
     ]
    }
   ],
   "source": [
    "text=TextBlob(customer_tweet) # neutral\n",
    "print(text.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "ccc27369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.519, 'neu': 0.481, 'pos': 0.0, 'compound': -0.6597}\n"
     ]
    }
   ],
   "source": [
    "score=sa.polarity_scores(customer_tweet)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "2edaee7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# score=sa.polarity_scores(tweet_summary)\n",
    "# print(score.get('neu'))\n",
    "# print(score.get('neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ef8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d8c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
